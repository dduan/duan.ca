<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/">
    <channel>
        <title>Daniel Duan's Articles About Performance</title>
        <link>https://duan.ca/tag/performance/</link>
        <atom:link href="https://duan.ca/tag/performance/feed.xml" rel="self" type="application/rss+xml" />
            <item>
                <title>TOMLDecoder 0.4 is 800% Faster</title>
                <description>&#60;p&#62;I just released version 0.4.1 of &#60;a href=&#34;https://github.com/dduan/TOMLDecoder&#34;&#62;TOMLDecoder&#60;/a&#62;,
a TOML 1.0 parser,
and &#60;a href=&#34;https://developer.apple.com/documentation/swift/codable&#34;&#62;decoder&#60;/a&#62; implemented in pure Swift.
When decoding a TOMLDocument such as &#60;a href=&#34;https://github.com/dduan/TOMLDecoder/blob/cea8f0bee33f37e0fcc33b566a742485c71196e7/Sources/Resources/fixtures/twitter.toml&#34;&#62;this twitter payload&#60;/a&#62;,
TOMLDecoder 0.4.1 is roughly 800% faster by wall clock time than 0.3.x.
In this post, Iâ€™ll discuss how this was achieved.&#60;/p&#62;
&#60;p&#62;&#60;em&#62;tl;dr: among other things,
the gains comes from making the parsing algorithm lazier,
and eliminating overheads from bound checking when accessing substrings.&#60;/em&#62;&#60;/p&#62;
&#60;h2&#62;The Benchmark&#60;/h2&#62;
&#60;p&#62;TOMLDecoder now includes benchmarks implemented with &#60;a href=&#34;https://github.com/ordo-one/package-benchmark&#34;&#62;ordo-one/package-benchmark&#60;/a&#62;.
I plotted the median from the aforementioned benchmark results below.
Each chart includes data points for deserializing the TOML document,
and decoding it on top.
(Unsurprisingly, decoding takes a bit longer.)&#60;/p&#62;
&#60;p&#62;The results show
wall clock time,
CPU instructions,
as well as retain count all trending down significantly.&#60;/p&#62;
&#60;p&#62;In addition to the before and after,
there&#39;s an extra data point measured specifically prior to adopting Swift&#39;s &#60;code&#62;Span&#60;/code&#62;.
More on that later.&#60;/p&#62;
&#60;iframe id=&#34;benchmark-iframe&#34; src=&#34;/assets/2025/12/tomldecoder-0.4.0-benchmark-charts.html&#34; width=&#34;100%&#34; height=&#34;1200&#34; frameborder=&#34;0&#34; style=&#34;border: none; display: block; margin: 20px 0; min-height: 1200px;&#34;&#62;&#60;/iframe&#62;
&#60;script&#62;
window.addEventListener(&#39;message&#39;, function(event) {
    if (event.data.type === &#39;resize&#39;) {
        const iframe = document.getElementById(&#39;benchmark-iframe&#39;);
        if (iframe) {
            iframe.style.height = event.data.height + &#39;px&#39;;
            iframe.style.transition = &#39;none&#39;;
        }
    }
});
&#60;/script&#62;
&#60;h2&#62;How to make a parser go fast&#60;/h2&#62;
&#60;h3&#62;Improving data structure and algorithms&#60;/h3&#62;
&#60;p&#62;... also known as cheating.
Yes, really.&#60;/p&#62;
&#60;p&#62;In 0.3.x, &#60;code&#62;TOMLDecoder&#60;/code&#62; behaves like &#60;a href=&#34;https://developer.apple.com/documentation/foundation/jsonserialization&#34;&#62;JSONSerialization&#60;/a&#62;.
When you ask it to decode TOML data,
with &#60;code&#62;TOMLDecoder.tomlTable(from:)&#60;/code&#62;
it goes through the entire document,
creates matching container structures within it.
For each TOML table, it creates a &#60;code&#62;[String: Any]&#60;/code&#62;,
for each TOML array, it creates a &#60;code&#62;[Any]&#60;/code&#62;.
When a table contains an array,
for example,
a corresponding &#60;code&#62;[&#38;quot;key&#38;quot;: [...]]&#60;/code&#62; entry is created to match.
Along the way, the parser also validates the leaf types,
so things like a ill-formed date causes an error to be thrown.
The end result is a &#60;code&#62;[String: Any]&#60;/code&#62; in which
everything is known to be valid.&#60;/p&#62;
&#60;p&#62;A number of things are slow in this process:&#60;/p&#62;
&#60;ul&#62;
&#60;li&#62;The frequent creation and subsequent usage of intermediary Swift arrays and dictionaries require heap allocations.&#60;/li&#62;
&#60;li&#62;Validating every leaf value takes time.&#60;/li&#62;
&#60;li&#62;Retrieved values are &#60;code&#62;Any&#60;/code&#62;s, so you have to cast it to the expected type to consume them.&#60;/li&#62;
&#60;/ul&#62;
&#60;p&#62;TOMLDecoder 0.4 does away with all of that.&#60;/p&#62;
&#60;p&#62;To represent the containers,
and leaf values,
0.4 introduces some light-weight structs,
These structs don&#39;t manage the actual memory used to store their contents.
As the parser work through the bytes of a TOML document,
it creates these light weight data types to record the shape of the document,
as well as the byte-offsets of the leaf values.
These intermediary data are stored in a centralized location
to avoid unnecessary heap allocations.&#60;/p&#62;
&#60;p&#62;Here&#39;s what I mean by &#38;quot;cheating&#38;quot;:
during this phase,
the parser doesn&#39;t do much validation of the leaf values.
What it does is more akin to &#38;quot;lexing&#38;quot;,
it finds the tokens that could represent a leaf value,
and remembers where they are.
No work is done to actually validate and create the leaf values.&#60;/p&#62;
&#60;p&#62;To retrieve any values from the result,
you must state what type is expected:&#60;/p&#62;
&#60;pre&#62;&#60;code class=&#34;language-swift&#34;&#62;// a valid TOML document is always a table at the root level
let serverIP = try TOMLTable(source: tomlString)
	.string(forKey: &#38;quot;ip&#38;quot;) // validate this token as a `String`
&#60;/code&#62;&#60;/pre&#62;
&#60;p&#62;This is an API change.
It delays the validation work,
and helps avoid conversions from &#60;code&#62;Any&#60;/code&#62;.
If you only need one field,
no validation is necessary on the rest of the leaf values in the entire document.&#60;/p&#62;
&#60;p&#62;Swift&#39;s decoding APIs ask for typed access:
if your &#60;code&#62;Codable&#60;/code&#62; type has a &#60;code&#62;Date&#60;/code&#62; field,
you ask the container for a &#60;code&#62;Date&#60;/code&#62;,
if the matching value at the spot is of a different type,
an error is thrown.
So the more efficient access pattern benefits the decoding process as well.&#60;/p&#62;
&#60;h3&#62;Avoiding bound checks&#60;/h3&#62;
&#60;p&#62;A major source of slowness in TOMLDecoder 0.3.x is the cost of bound checks in Swift.
The parser holds a reference to the original string,
and hands &#60;code&#62;Substring&#60;/code&#62;s to small functions to descend on.
A typical piece of the parser might look like this:&#60;/p&#62;
&#60;pre&#62;&#60;code class=&#34;language-swift&#34;&#62;func skipWhitespaces(_ text: inout Substring) {
    let bytes = text.utf8
    var i = bytes.startIndex
    while i &#38;lt; bytes.endIndex {
        if !isWhitespace(bytes[i]) { // bound checks!
            break
        }
        bytes.formIndex(after: &#38;amp;i)
    }
    text = Substring(bytes[i...])
}
&#60;/code&#62;&#60;/pre&#62;
&#60;p&#62;To avoid out-of-bound access,
Swift inserts logic that checks the validity of the index
for every subscript access of the string&#39;s buffer.
A parser does a whole lot of that.
The cost of these bound checks seriously adds up.&#60;/p&#62;
&#60;p&#62;Since the release of TOMLDecoder 0.3.0,
Swift has gained a whole set of features that led to the introduction of &#60;a href=&#34;https://github.com/swiftlang/swift-evolution/blob/main/proposals/0447-span-access-shared-contiguous-storage.md&#34;&#62;Span&#60;/a&#62;.
&#60;code&#62;Span&#60;/code&#62; is built on compile-time lifetime checks.
These checks guarantee the safety when accessing its content.
The same function updated for &#60;code&#62;Span&#60;/code&#62; looks extremely similar to the original:&#60;/p&#62;
&#60;pre&#62;&#60;code class=&#34;language-swift&#34;&#62;func skipWhitespace(
    bytes: Span&#38;lt;UTF8.CodeUnit&#38;gt;, // aka Span&#38;lt;UInt8&#38;gt;
    remainingBytes: inout Range&#38;lt;Int&#38;gt;,
) {
    var i = remainingBytes.lowerBound
    while i &#38;lt; bytes.count {
        if !isWhitespace(bytes[i]) { break }
        i += 1
    }
    remainingBytes = i ..&#38;lt; remainingBytes.upperBound
}
&#60;/code&#62;&#60;/pre&#62;
&#60;p&#62;Here,
the subscript access of &#60;code&#62;bytes&#60;/code&#62; does not incur a bound check!
This created significant performance gains as shown in the benchmark results.&#60;/p&#62;
&#60;p&#62;&#60;em&#62;Here&#39;s the kicker&#60;/em&#62;.
The bound checks are eliminated
because the compiler is confident that the access is safe by construction.
If you make a mistake that would lead to unsafe access,
Swift will refuse to compile your code.
But &#60;code&#62;Span&#60;/code&#62; is a language feature that requires new language runtime.
You cannot use it on older operating systems.
There&#39;s other, older ways to avoid bound checks,
using &#60;code&#62;UnsafeBufferPointer&#60;/code&#62;s.
The problem of doing so is that you are responsible for ensuring that the access is safe.
In particular, the point of access must occur in a valid scope for the pointer.
A piece of parser using such API may look like this:&#60;/p&#62;
&#60;pre&#62;&#60;code class=&#34;language-swift&#34;&#62;func skipWhitespace(
    bytes: UnsafeBufferPointer&#38;lt;UTF8.CodeUnit&#38;gt;,
    remainingBytes: inout Range&#38;lt;Int&#38;gt;,
) {
    var i = remainingBytes.lowerBound
    while i &#38;lt; bytes.count {
        if !isWhitespace(bytes[i]) { break }
        i += 1
    }
    remainingBytes = i ..&#38;lt; remainingBytes.upperBound
}
&#60;/code&#62;&#60;/pre&#62;
&#60;p&#62;But WAIT!  This code using the buffer pointer look extremely similar to the &#60;code&#62;Span&#60;/code&#62; version!
And if you think carefully,
the requirement for maintaining valid scope for the &#60;code&#62;UnsafeBufferPointer&#60;/code&#62; is already &#60;em&#62;enforced&#60;/em&#62; for any &#60;code&#62;Span&#60;/code&#62;s, syntactically!&#60;/p&#62;
&#60;p&#62;Enter &#60;a href=&#34;https://nshipster.com/swift-gyb/&#34;&#62;gyb&#60;/a&#62;. A script that Swift uses to generate repetitive code in the complier.
In TOMLDecoder 0.4,
the parser implementation uses it to generate 2 version of the same set of parsing logic:&#60;/p&#62;
&#60;pre&#62;&#60;code class=&#34;language-swift&#34;&#62;configs = [
    (&#38;quot;Span&#38;lt;UInt8&#38;gt;&#38;quot;, &#38;quot;@available(iOS 26, macOS 26, watchOS 26, tvOS 26, visionOS 26, *)&#38;quot;),
    (&#38;quot;UnsafeBufferPointer&#38;lt;UInt8&#38;gt;&#38;quot;, &#38;quot;@available(iOS 13, macOS 10.15, watchOS 6, tvOS 13, visionOS 1, *)&#38;quot;),
]
}%
% for byte_type, availability in configs:
${availability}
func parse(bytes: ${byte_type}) throws -&#38;gt; TOMLTable {
	// same code
}
% end
&#60;/code&#62;&#60;/pre&#62;
&#60;p&#62;... and there&#39;s a single place that checks for the OS at runtime:&#60;/p&#62;
&#60;pre&#62;&#60;code class=&#34;language-swift&#34;&#62;let source: String = ... // TOML string
if #available(iOS 26, macOS 26, watchOS 26, tvOS 26, visionOS 26, *) {
    let bytes = source.utf8Span.span
    try parse(bytes: bytes)
} else {
    try source.withUTF8 { try parse(bytes: $0) }
}
&#60;/code&#62;&#60;/pre&#62;
&#60;p&#62;The beauty here,
is that the compiler does all the work to ensure the access to the &#60;code&#62;Span&#60;/code&#62;
as well as the buffer pointer are safe,
because the logic that does the accessing are identical thanks to &#60;code&#62;gyb&#60;/code&#62;.&#60;/p&#62;
&#60;h2&#62;Conclusion&#60;/h2&#62;
&#60;p&#62;In reality, there are a ton of other optimizations applied in TOMLDecoder 0.4.
For example,
instead of doing dictionary look ups,
looking up things from a TOMLDocument actually involves a linear search.
I know, I know, this goes against what we were taught in CS.
But in modern computers,
and for typical sizes of TOML documents,
a linear search is often faster that computing a hash value,
and the subsequent lookups.&#60;/p&#62;
&#60;p&#62;As part of the release,
the project also gained a bunch of infra improvements.&#60;/p&#62;
&#60;ul&#62;
&#60;li&#62;It has a &#60;a href=&#34;https://www.swift.org/documentation/docc/&#34;&#62;DocC&#60;/a&#62;-based &#60;a href=&#34;https://dduan.github.io/TOMLDecoder/main/documentation/tomldecoder/&#34;&#62;documentation site&#60;/a&#62;.&#60;/li&#62;
&#60;li&#62;The entirety of the &#60;a href=&#34;https://github.com/toml-lang/toml-test&#34;&#62;official test suite&#60;/a&#62; is now programmatically imported as unit tests.&#60;/li&#62;
&#60;li&#62;The source code style is now enforced by &#60;a href=&#34;https://github.com/nicklockwood/SwiftFormat&#34;&#62;swiftformat&#60;/a&#62;.&#60;/li&#62;
&#60;li&#62;Platform checks are more comprehensive and modern on CI.&#60;/li&#62;
&#60;li&#62;Benchmarks are now modernized with &#60;a href=&#34;https://github.com/ordo-one/package-benchmark&#34;&#62;ordo-one/package-benchmark&#60;/a&#62;&#60;/li&#62;
&#60;/ul&#62;
&#60;p&#62;I think of this release as a preparation for a eventual 1.0 release,
which will support the &#60;a href=&#34;https://forums.swift.org/t/the-future-of-serialization-deserialization-apis/78585/171&#34;&#62;new deserialization APIs from Swift&#60;/a&#62;.&#60;/p&#62;
&#60;p&#62;Even through I went through some optimizations for speed in this post,
I still have a bunch of ideas I want to try to squeeze out more performance gains.
That&#39;s exciting.&#60;/p&#62;
</description>
                <pubDate>Wed, 10 Dec 2025 17:44:34 -0800</pubDate>
                <link>https://duan.ca/2025/12/10/TOMLDecoder-0.4.1/</link>
                <guid isPermaLink="true">https://duan.ca/2025/12/10/TOMLDecoder-0.4.1/</guid>
            </item>
    </channel>
</rss>